{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolvendo Pacman\n",
    "\n",
    "O objetivo deste trabalho é de resolver o jogo Pacman, de forma estática, utilizando os algoritmos de busca aprendidos nas aulas de MC906/MO416.\n",
    "\n",
    "Matheus Silva Capeletti RA 203587\n",
    "\n",
    "João Paulo Soubihe RA 151106\n",
    "\n",
    "Lucas 182371\n",
    "\n",
    "Karol Daniela Cala Pinzón RA 264308\n",
    "\n",
    "Johana Marisol Saravia Bulla RA 264319\n",
    "\n",
    "## Algoritmos utilizados\n",
    "1. Breadth first search\n",
    "2. Depth first search\n",
    "3. Greedy Best First search\n",
    "4. A*\n",
    "5. Hill climbing search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representação do problema e seus estados\n",
    "\n",
    "Como forma de facilitar nosso trabalho, usamos a estrutura da ferramenta AIMA, dada como auxílio para o desenvolvimento do nosso projeto. Aproveitamos a classe **__Node__** para armazenar o estado, que nada mais seria que as coordenadas (x, y) descrevendo a posição no maze.\n",
    "\n",
    "Essa classe contém alguns métodos que nos serão muito úteis, como o método *path*, que nos dá o caminho percorrido até ali pela busca, ou o *expand* que nos retorna uma lista de nós que podemos seguir a partir das ações disponíveis.\n",
    "\n",
    "Quanto aos métodos de busca, por estarmos aproveitando a estrutura dada também seguiu a mesma lógica do AIMA.\n",
    "\n",
    "Abaixo é possível ver a definição do problema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PacmanProblem(Problem):\n",
    "    def __init__(self, initial, goal, maze=None):\n",
    "        self.initial = initial\n",
    "        self.goal = goal\n",
    "        if maze == None:\n",
    "            self.maze, self.mazeY, self.mazeX = rM.readMaze()\n",
    "        else:\n",
    "            self.maze, self.mazeY, self.mazeX = rM.readMaze(maze)\n",
    "    \n",
    "    # for a given position returns the adjacent positions that are gray paths\n",
    "    def adjacent(self, position):\n",
    "        adjacent = []\n",
    "        # left\n",
    "        if self.maze[position[0], position[1]-1] == 2:\n",
    "            if position[1] -1 < 0:\n",
    "                adjacent.append((position[0], self.mazeX -1))\n",
    "            else:\n",
    "                adjacent.append((position[0], position[1]-1))\n",
    "        # right\n",
    "        if position[1] + 1 == self.mazeX and self.maze[position[0], 0] == 2:\n",
    "            adjacent.append((position[0], 0))\n",
    "        elif position[1] + 1 < self.mazeX and self.maze[position[0], position[1]+1] == 2:\n",
    "            adjacent.append((position[0], position[1]+1))\n",
    "                \n",
    "        # up\n",
    "        if self.maze[position[0]-1, position[1]] == 2:\n",
    "            if position[0] -1 < 0:\n",
    "                adjacent.append((self.mazeY-1, position[1]))\n",
    "            else:\n",
    "                adjacent.append((position[0]-1, position[1]))\n",
    "        # down\n",
    "        if position[0] + 1 == self.mazeY and self.maze[0, position[1]] == 2:\n",
    "            adjacent.append((0, position[1]))\n",
    "        elif position[0] + 1 < self.mazeY and self.maze[position[0]+1, position[1]] == 2:\n",
    "            adjacent.append((position[0]+1, position[1]))\n",
    "        \n",
    "        return adjacent\n",
    "\n",
    "     # returns the possible child states for the given state\n",
    "    def actions(self, state):\n",
    "        return self.adjacent(state)\n",
    "\n",
    "    # the goal is reached if all positions that are reachable through the initial state are in the solution \n",
    "    # and the first and last positions in the solution are the initial position and goal position\n",
    "    def goal_test(self, states):\n",
    "        return states[-1] == self.goal and states[0] == self.initial\n",
    "    \n",
    "    def result(self, state, action):\n",
    "        return action\n",
    "    \n",
    "    def path_cost(self, c, position1, action, position2):\n",
    "        # Se as posicoes n forem adjacentes entao nao ha um caminho direto de pos1 pra pos2\n",
    "        if abs(position1[0] - position2[0]) > 1 or abs(position1[1] - position2[1]) > 1:\n",
    "            return math.inf\n",
    "        return c+1\n",
    "\n",
    "    # Retorna uma lista com todas as posicoes alcancaveis a partir da posicao dada, inclusive essa posicao\n",
    "    def reachable_positions(self, startPosition):\n",
    "        positions = []\n",
    "        queue = [startPosition]\n",
    "\n",
    "        while queue:\n",
    "            position = queue.pop(0)\n",
    "            positions.append(position)\n",
    "            actions = self.adjacent(position)\n",
    "\n",
    "            for action in actions:\n",
    "                alreadyVisited = False\n",
    "                for item in positions:\n",
    "                    if item == action:\n",
    "                        alreadyVisited = True\n",
    "                        break\n",
    "\n",
    "                if alreadyVisited == False:\n",
    "                    queue.append(action)\n",
    "\n",
    "        return set(positions)\n",
    "\n",
    "\n",
    "    def h(self, node):\n",
    "        return self.distance(node.state, self.goal)\n",
    "\n",
    "    def g(self, node):\n",
    "        return node.path_cost\n",
    "    \n",
    "    def h2(self, node):\n",
    "        return self.euclidean_distance(node.state, self.goal)\n",
    "    \n",
    "       # Calcula a distancia entre duas posicoes, valido apenas para posicoes que fazem parte da sol\n",
    "    @functools.lru_cache(maxsize=4096)\n",
    "    def distance(self, position1, position2, lim=100000):\n",
    "        if position1 == position2:\n",
    "            return 0\n",
    "   # dicicionario com formato { item: [distancia, visitado (0 = nao, 1 = sim)], ... }\n",
    "        d = dict.fromkeys(self.reachable_positions(position1), [math.inf, 0])\n",
    "        d[position1] = [0, 0]\n",
    "\n",
    "        i = 0\n",
    "        while min({l[1] for l in d.values()}) == 0 and i < lim:\n",
    "            m = math.inf\n",
    "            current = None\n",
    "            for k, v in d.items():\n",
    "                if v[1] == 0 and v[0] < m:\n",
    "                    current = k\n",
    "                    m = v[0]\n",
    "\n",
    "            d[current] = [m, 1]\n",
    "\n",
    "            neighbors = self.adjacent(current)\n",
    "            for neighbor in neighbors:\n",
    "                if d[neighbor][1] == 0 and m + 1 < d[neighbor][0]:\n",
    "                    d[neighbor] = [m + 1, 0]\n",
    "                    if neighbor == position2:\n",
    "                        return m + 1\n",
    "\n",
    "            current = None\n",
    "            i = i + 1\n",
    "\n",
    "        try:\n",
    "            return d[position2][0]\n",
    "        except KeyError:\n",
    "            return math.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função adjacente retorna para uma dada posição áreas cinzas adjacentes para as quais é possível se movimentar, não criamos uma abstração do tipo 'left', 'right', 'up', 'down' pois não consideramos necessário para a resolução do problema.\n",
    "\n",
    "Definimos o *goal_test* como: dada uma sequência de posições a primeira posição da sequência é a posição inicial do problema e a última posição é a posição de objetivo do problema, não verificamos se os itens intermediários são de fato adjacentes pois isso seria custoso nos algoritmos de busca.\n",
    "\n",
    "A função *reachable_positions* retorna uma lista de posições que podem ser alcançadas a partir de uma posição dada como argumento.\n",
    "\n",
    "O algoritmo *distance* acima calcula a **distância** entre dois pontos, se eles puderem ser atingidos um a partir do outro.\n",
    "Inicialmente, ele checa se os pontos passados se referem a mesma posição, em caso positivo, já temos nossa resposta! (e nos poupa um bom processamento). Em caso negativo *distance* usa uma função auxiliar (*reachable_positions*) que nos retorna um dicionário onde dada a chave (coordenadas da respectiva posição) temos um valor (uma lista (distancia, visitado)).\n",
    "Enquanto não existir elementos ainda não visitados, avaliamos o **mais próximo** dentre estes,  da posição corrente da nossa busca.\n",
    "\n",
    "Com esse nó avaliado no loop, para cada posição adjacente não avaliada, incrementa-se a distância respectiva.\n",
    "\n",
    "Esse processo continua até que se visite a posição dada por _position2_ \n",
    "\n",
    "Ou seja, em resumo, simulamos os passos a serem dados para nosso agente chegar de um ponto A (*position1*) a um ponto B (*position2*) e projetamos o menor caminho possível, sustentado pela estratégia de que iniciamos cada uma das \"buscas parciais\" do nó com a menor distância, nos termos de manhattan, a cada iteração."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal Test\n",
    "\n",
    "Simplesmente é passado o path contendo o novo node a ser avaliado e, como estrutura do problema, nosso goal.\n",
    "Caso o goal esteja contido no path achamos nosso objetivo! O agente então poderá agir.\n",
    "\n",
    "Aqui é importante lembrar que nosso agente realiza somente buscas offline, ou seja, antes de realizar uma ação, a busca é executada e uma solução é encontrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Breadth first search\n",
    "\n",
    "**Completo:** Sim.\n",
    "\n",
    "**Ótimo:** Não.\n",
    "\n",
    "**Complexidade de tempo:** Toda vez que é feita uma expansão até 3 novos nós são adicionados à fila de prioridade, portanto **O**($3^{d+1}$), onde d+1 é a profundidade da solução mais rasa (mais próxima do estado inicial).\n",
    "\n",
    "**Complexidade de memória:** O algoritmo armazena os nós expandidos em uma fila de prioridade e os visitados em uma lista, poranto **O**($3^{d+1}$), igual à complexidade de tempo.\n",
    "\n",
    "**Resultados:**\n",
    "\n",
    "*Problema1:* Tempo de execução: 0.01 segundos, iterações: 136, posições distintas visitadas: 14\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"550\" height=\"550\" src=\"Images/Problem1BFSFinalState.png\">\n",
    "</p>\n",
    "\n",
    "*Problema2:* Tempo de execução: 0.01 segundos, iterações: 159, posições distintas visitadas: 23\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"550\" height=\"550\" src=\"Images/Problem2BFSFinalState.png\">\n",
    "</p>\n",
    "\n",
    "*Problema3:* Tempo de execução: 0.003 segundos, iterações: 66, posições distintas visitadas: 14\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"550\" height=\"550\" src=\"Images/Problem3BFSFinalState.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_breadth_search_for_vis(problem, iterLim=100000):\n",
    "    \"\"\"Search through the successors of a problem to find a goal.\n",
    "    The argument frontier should be an empty queue.\n",
    "    Don't worry about repeated paths to a state. [Figure 3.7]\"\"\"\n",
    "\n",
    "    # we use these two variables at the time of visualisations\n",
    "    iterations = 0\n",
    "    all_node_colors = []\n",
    "    node_colors = {k: 'white' for k in set(problem.reachable_positions(problem.initial))}\n",
    "\n",
    "    # Adding first node to the queue\n",
    "    frontier = deque([Node(problem.initial)])\n",
    "\n",
    "    node_colors[Node(problem.initial).state] = \"orange\"\n",
    "    iterations += 1\n",
    "    all_node_colors.append(dict(node_colors))\n",
    "\n",
    "    explored = []\n",
    "    while frontier:\n",
    "        # Popping first node of queue\n",
    "        node = frontier.popleft()\n",
    "        explored.append(node.state)\n",
    "        # modify the currently searching node to red\n",
    "        node_colors[node.state] = \"red\"\n",
    "        iterations += 1\n",
    "        all_node_colors.append(dict(node_colors))\n",
    "\n",
    "        if problem.goal_test([node.state for node in node.path()]):\n",
    "            # modify goal node to green after reaching the goal\n",
    "            node_colors[node.state] = \"green\"\n",
    "            iterations += 1\n",
    "            all_node_colors.append(dict(node_colors))\n",
    "            return (iterations, all_node_colors, node)\n",
    "\n",
    "        for n in node.expand(problem):\n",
    "            if n.state not in explored and n not in frontier:\n",
    "                frontier.append(n)\n",
    "                node_colors[n.state] = \"orange\"\n",
    "                iterations += 1\n",
    "                all_node_colors.append(dict(node_colors))\n",
    "\n",
    "        # modify the color of explored nodes to gray\n",
    "        node_colors[node.state] = \"gray\"\n",
    "        iterations += 1\n",
    "        all_node_colors.append(dict(node_colors))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Depth first search\n",
    "\n",
    "**Completo:** Sim.\n",
    "\n",
    "**Ótimo:** Não.\n",
    "\n",
    "**Complexidade de tempo:** Toda vez que é feita uma expansão até 3 novos nós são adicionados à fila de prioridade, portanto **O**($3^{d+1}$), onde d+1 é a profundidade da solução mais rasa (mais próxima do estado inicial).\n",
    "\n",
    "**Complexidade de memória:** O algoritmo armazena os nós expandidos em uma fila de prioridade e os visitados em uma lista, poranto **O**($3^{d+1}$), igual à complexidade de tempo.\n",
    "\n",
    "**Resultados:**\n",
    "\n",
    "*Problema1:* Tempo de execução: 0.009 segundos, iterações: 317, posições distintas visitadas: 24\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"550\" height=\"550\" src=\"Images/Problem1DFSFinalState.png\">\n",
    "</p>\n",
    "\n",
    "*Problema2:* Tempo de execução: 0.01 segundos, iterações: 348, posições distintas visitadas: 27\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"550\" height=\"550\" src=\"Images/Problem2DFSFinalState.png\">\n",
    "</p>\n",
    "\n",
    "*Problema3:* Tempo de execução: 0.002 segundos, iterações: 94, posições distintas visitadas: 18\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"550\" height=\"550\" src=\"Images/Problem3DFSFinalState.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_depth_search_for_vis(problem, iterLim=100000):\n",
    "    \"\"\"Search through the successors of a problem to find a goal.\n",
    "    The argument frontier should be an empty queue.\n",
    "    Don't worry about repeated paths to a state. [Figure 3.7]\"\"\"\n",
    "\n",
    "    # we use these two variables at the time of visualisations\n",
    "    iterations = 0\n",
    "    all_node_colors = []\n",
    "    node_colors = {k : 'white' for k in set(problem.reachable_positions(problem.initial))}\n",
    "\n",
    "    # Adding first node to the stack\n",
    "    frontier = [Node(problem.initial)]\n",
    "\n",
    "    node_colors[Node(problem.initial).state] = \"orange\"\n",
    "    iterations += 1\n",
    "    all_node_colors.append(dict(node_colors))\n",
    "\n",
    "    explored = []\n",
    "    while len(frontier) > 0 and iterations < iterLim:\n",
    "        # Popping first node of stack\n",
    "        node = frontier.pop()\n",
    "\n",
    "        explored.append(node.state)\n",
    "        # modify the currently searching node to red\n",
    "        node_colors[node.state] = \"red\"\n",
    "        iterations += 1\n",
    "        all_node_colors.append(dict(node_colors))\n",
    "\n",
    "        if problem.goal_test([node.state for node in node.path()]):\n",
    "            # modify goal node to green after reaching the goal\n",
    "            node_colors[node.state] = \"green\"\n",
    "            iterations += 1\n",
    "            all_node_colors.append(dict(node_colors))\n",
    "            return (iterations, all_node_colors, node)\n",
    "\n",
    "        for n in node.expand(problem):\n",
    "            if n.state not in explored and n not in frontier:\n",
    "                frontier.append(n)\n",
    "                node_colors[n.state] = \"orange\"\n",
    "                iterations += 1\n",
    "                all_node_colors.append(dict(node_colors))\n",
    "            \n",
    "\n",
    "        # modify the color of explored nodes to gray\n",
    "        node_colors[node.state] = \"gray\"\n",
    "        iterations += 1\n",
    "        all_node_colors.append(dict(node_colors))\n",
    "\n",
    "    return (iterations, all_node_colors, node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heurísticas\n",
    "\n",
    "As Heurísticas elaboradas foram determinantes, principalmente para os Informed Search Algorithms, onde seu resultado h(n) é contabilizado juntamente do path cost   g(n) para o agente decidir o próximo passo a ser avaliado. Podendo ou não indicar a melhor solução.\n",
    "\n",
    "Para o problema do Pacman nossas heurísticas estão voltadas para achar o menor caminho possível para nosso agente chegar ao *goal*, não foram parametrizados as moedas espalhadas pelo mapa.\n",
    "\n",
    "Com uma busca pela bibliografia e na internet achamos duas heurísticas bastante utilizadas em problemas desse tipo.\n",
    "\n",
    "### Distância\n",
    "\n",
    "Baseado na real distância que o agente irá percorrer. Considera o número de passos que serão dados, o número de ações que serão tomadas.\n",
    "\n",
    "O processamento é um pouco mais custoso do que o normal, devido a essa metodologia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distância Euclideana\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(self, position1, position2):\n",
    "        if self.reachable(position1, position2) is False:\n",
    "            return math.inf\n",
    "        \n",
    "        deltaX1 = (position2[0] - position1[0])**2\n",
    "        deltaY1 = (position2[1] - position1[1])**2\n",
    "        return (deltaX1 + deltaY1)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa heurística é bem mais direta em termos de lógica e processamento de dados. \n",
    "\n",
    "A distância euclidiana avalia simplismente, a distância em linha reta, do ponto A ao ponto B, que no caso de nosso algoritmo de busca seriam o ponto de avaliação atual ao goal.\n",
    "\n",
    "Em primeiro lugar, checamos se os dois pontos são alcançáveis. Se sim, calculamos a distância segundo a fórmula de Euclides:\n",
    "\n",
    "$\\sqrt{(x2 - x1)² + (y2 - y1)²)}$\n",
    "\n",
    "Com a recorrência de sempre projetarmos o sucessor do estado analisado como o que nos dá o menor custo, sempre teremos respeitado o fato que o custo de n ao goal, não será maior que o custo de seu sucessor ao mesmo goal mais o passo de n a esse sucessor. De uma forma explicativa, na pior das hipóteses o agente deverá fazer um \"desvio\" no caminho, caso faça uma escolha não ótima, por exemplo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Greedy Best first search\n",
    "\n",
    "O _Greedy Best First Search Algoritm_ funciona de maneira muito parecida com o _A* Search_. A partir de um nó inicial, avalia-se o custo f(n) do caminho a cada um de seus possíveis destinos, de acordo com as ações que poderão ser tomadas.\n",
    "\n",
    "Onde,\n",
    "\n",
    "  f(n) = g(n) + h(n) \n",
    " \n",
    "  g(n) é o custo do caminho tomado e h(n) é o custo segundo a heurística adotada para a avaliação.\n",
    "\n",
    "\n",
    "Seu nome greedy (ganancioso) se dá pelo fato de que após uma ação tomada, não faz mais parte da avaliação (até que se comprove que o caminho não se dá até o goal) os custos perantes as demais ações possíveis, os outros nós adjacentes no nosso caso.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"400\" height=\"400\" src=\"Greedy.png\">\n",
    "</p>\n",
    "\n",
    "Acima vemos uma imagem que ilustra o comportamento do algoritmo, vemos claramente a preferência pelo caminho mais barato ali naquele momento, sem levar em consideração outros passos.\n",
    "\n",
    "**Completo:** Não.\n",
    "\n",
    "**Ótimo:** Não.\n",
    "\n",
    "**Complexidade de tempo:** O(b^m). \n",
    "\n",
    "**Complexidade de memória:** O(b^m).\n",
    "\n",
    "Em ambos b é a quantidade de nós que a atual posição pode expandir e m refere-se à profundidade da busca.\n",
    "Mas é importante ressaltar que em alguns casos, a situação pode favorecer e se tornar um algoritmo bem eficiente, como vimos através dos resultados obtidos.\n",
    "O grande problema da greedy solution é o fato de não ter controle em situações de espaço infinito, ou em caminhos sem solução, por exemplo com loops (que acabarão por \"prender\" nosso agente num ciclo infinito). Outra situação ruim é que nem sempre optará pelo caminho menos custoso, o que no nosso caso não chegou a ser um problema, mas em situações de maior escala podem vir a ser um grande problema.\n",
    "\n",
    "**Resultados:**\n",
    "\n",
    "*Problema1:* Tempo de execução: 0.003 segundos, iterações: 47, posições distintas visitadas: 14\n",
    "\n",
    "*Problema2:* Tempo de execução: 0.004 segundos, iterações: 77, posições distintas visitadas: 23\n",
    "\n",
    "*Problema3:* Tempo de execução: 0.001 segundos, iterações: 47, posições distintas visitadas: 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_best_first_search(problem, h=None):\n",
    "    if h == None:\n",
    "        h = problem.h2\n",
    "    iterations, all_node_colors, node = best_first_graph_search_for_vis(problem, lambda n: h(n))\n",
    "    return (iterations, all_node_colors, node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. A*\n",
    "\n",
    "Abaixo segue a definição da busca A*, o método usa também outro método de busca chamado *best_first_graph_search_for_vis*, que será exibido depois:\n",
    "\n",
    "**Completo:** Sim.\n",
    "\n",
    "**Ótimo:** Não.\n",
    "\n",
    "**Complexidade de tempo:** Toda vez que é feita uma expansão até 3 novos nós são adicionados à fila de prioridade, portanto **O**($3^{d+1}$), onde d+1 é a profundidade da solução mais rasa (mais próxima do estado inicial).\n",
    "\n",
    "**Complexidade de memória:** O algoritmo armazena os nós expandidos em uma fila de prioridade e os visitados em uma lista, poranto **O**($3^{d+1}$), igual à complexidade de tempo.\n",
    "\n",
    "**Resultados:**\n",
    "\n",
    "*Problema1:* Tempo de execução: 0.13 segundos, iterações: 156, posições distintas visitadas: 18\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"550\" height=\"550\" src=\"Images/Problem1AstarFinalState.png\">\n",
    "</p>\n",
    "\n",
    "*Problema2:* Tempo de execução: 0.21 segundos, iterações: 182, posições distintas visitadas: 23\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"550\" height=\"550\" src=\"Images/Problem2AstarFinalState.png\">\n",
    "</p>\n",
    "\n",
    "*Problema3:* Tempo de execução: 0.02 segundos, iterações: 47, posições distintas visitadas: 14\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"550\" height=\"550\" src=\"Images/Problem3AstarFinalState.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_search_graph(problem, h=None, g=None):\n",
    "    if h is None:\n",
    "        h = problem.h\n",
    "    if g is None:\n",
    "        g = problem.g\n",
    "    iterations, all_node_colors, node = best_first_graph_search_for_vis(problem, lambda n: g(n) + h(n))\n",
    "    return iterations, all_node_colors, node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Hill climbing search\n",
    "\n",
    "Foi escolhido este método de busca local para encontrar mínimos da função distância (a distância entre o nó atual e o nó destino). Espera-se que o único mínimo encontrado seja o próprio nó destino pois é o ponto em que a função tem o seu mínimo global (0), além de que não é esperado mais nenhum mínimo local.\n",
    "\n",
    "**Completo:** Não. Foram encontrados casos em que o algoritmo se entrou em um caminho sem saída e determinou que este era o mínimo (o objetivo) pois não podia sair de lá, sendo que ele chegou a este lugar pois era a posição mais próxima ao nó destino dentre os vizinhos do nó anterior.\n",
    "\n",
    "**Ótimo:** Não\n",
    "\n",
    "**Complexidade de tempo:** No melhor dos casos o algoritmo implementado atravessaria uma reta até o objetivo se este existir, no pior dos casos ele pode precisar se mover pelo tabuleiro todo, sendo este delimitado apenas pelas circunstâncias do tabuleiro, devido à natureza do problema.\n",
    "\n",
    "**Complexidade de memória:** O algoritmo armazena todos os nós expandidos a partir do nó atual, para este problema, o número de nós adjacentes é limitado à 8, logo são armazenados até no máximo 9 nós ao mesmo tempo.\n",
    "\n",
    "**Resultados:**\n",
    "\n",
    "*Problema1:* Tempo de execução: 0.11 segundos, iterações: 12, posições distintas visitadas: 11\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"550\" height=\"550\" src=\"Images/Problem1HillClimbingFinalState.png\">\n",
    "</p>\n",
    "\n",
    "\n",
    "*Problema2:* Tempo de execução: 0.01 segundos, iterações: 2, posições distintas visitadas: 1\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"550\" height=\"550\" src=\"Images/Problem2HillClimbingFinalState.png\">\n",
    "</p>\n",
    "\n",
    "\n",
    "*Problema3:* Tempo de execução: 0.07 segundos, iterações: 15, posições distintas visitadas: 14\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"550\" height=\"550\" src=\"Images/Problem3HillClimbingFinalState.png\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_climbing_search(problem):\n",
    "    \"\"\"\n",
    "    Search for a local minimum following a certain optimization function\n",
    "    The function used for this problem was the distance function from the\n",
    "    actual point to the goal point. Which is the same used for our second heuristics informed search.\n",
    "    \"\"\"\n",
    "    # we use these two variables at the time of visualisations\n",
    "    iterations = 0\n",
    "    all_node_colors = []\n",
    "    node_colors = {k : 'white' for k in set(problem.reachable_positions(problem.initial))}\n",
    "    \n",
    "    frontier = [(Node(problem.initial))]\n",
    "    explored = set()\n",
    "    \n",
    "    # modify the color of frontier nodes to orange\n",
    "    node_colors[Node(problem.initial).state] = \"orange\"\n",
    "    iterations += 1\n",
    "    all_node_colors.append(dict(node_colors))\n",
    "    \n",
    "    while True:\n",
    "        # Popping first node of stack\n",
    "        node = frontier.pop()\n",
    "\n",
    "        # modify the currently searching node to red\n",
    "        node_colors[node.state] = \"red\"\n",
    "        iterations += 1\n",
    "        all_node_colors.append(dict(node_colors))\n",
    "        \n",
    "        neighbors = node.expand(problem)\n",
    "        if not neighbors:\n",
    "            break\n",
    "        # find the minimum between the neighbors\n",
    "        neighbor = argmin_random_tie(neighbors, key=lambda node: problem.h2(node))\n",
    "        \n",
    "        # trying to find minimum \n",
    "        if problem.h2(neighbor) > problem.h2(node):\n",
    "            # node is already the local minimum\n",
    "            node_colors[node.state] = \"green\"\n",
    "            all_node_colors.append(dict(node_colors))\n",
    "            return iterations, all_node_colors, node\n",
    "        \n",
    "        # expand only for painting\n",
    "        frontier.extend(child for child in node.expand(problem)\n",
    "                        if child.state not in explored and\n",
    "                        child not in frontier)\n",
    "        \n",
    "        for n in frontier:\n",
    "            # modify the color of frontier nodes to orange\n",
    "            node_colors[n.state] = \"orange\"\n",
    "            all_node_colors.append(dict(node_colors))\n",
    "        \n",
    "        frontier.clear()\n",
    "        frontier.append(neighbor) # append the last\n",
    "            \n",
    "        explored.add(node.state)\n",
    "\n",
    "        # modify the color of explored nodes to gray\n",
    "        node_colors[node.state] = \"gray\"\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo segue a definição do método *best_first_graph_search_for_vis*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_first_graph_search_for_vis(problem, f):\n",
    "    iterations = 0\n",
    "    all_node_colors = []\n",
    "    node_colors = {k: 'white' for k in set(problem.reachable_positions(problem.initial))}\n",
    "\n",
    "    node = Node(problem.initial)\n",
    "\n",
    "    node_colors[node.state] = \"red\"\n",
    "    iterations += 1\n",
    "    all_node_colors.append(dict(node_colors))\n",
    "\n",
    "    frontier = PriorityQueue()\n",
    "    frontier.append(node, f(node))\n",
    "\n",
    "    node_colors[node.state] = \"orange\"\n",
    "    iterations += 1\n",
    "    all_node_colors.append(dict(node_colors))\n",
    "\n",
    "    explored = set()\n",
    "    while not frontier.isEmpty():\n",
    "        node = frontier.pop()\n",
    "\n",
    "        node_colors[node.state] = \"red\"\n",
    "        iterations += 1\n",
    "        all_node_colors.append(dict(node_colors))\n",
    "\n",
    "        if problem.goal_test([node.state for node in node.path()]):\n",
    "            node_colors[node.state] = \"green\"\n",
    "            iterations += 1\n",
    "            all_node_colors.append(dict(node_colors))\n",
    "            return (iterations, all_node_colors, node)\n",
    "\n",
    "        explored.add(node.state)\n",
    "        for child in node.expand(problem):\n",
    "            if child.state not in explored and child not in frontier:\n",
    "                frontier.append(child, f(child))\n",
    "                node_colors[child.state] = \"orange\"\n",
    "                iterations += 1\n",
    "                all_node_colors.append(dict(node_colors))\n",
    "            elif child in frontier:\n",
    "                incumbent = frontier[child]\n",
    "                if f(child) < f(incumbent):\n",
    "                    del frontier[incumbent]\n",
    "                    frontier.append(child, f(child))\n",
    "                    node_colors[child.state] = \"orange\"\n",
    "                    iterations += 1\n",
    "                    all_node_colors.append(dict(node_colors))\n",
    "\n",
    "        node_colors[node.state] = \"gray\"\n",
    "        iterations += 1\n",
    "        all_node_colors.append(dict(node_colors))\n",
    "    return iterations, all_node_colors, node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método utiliza uma fila de prioridade, itens com menor valor saem primeiro da fila e a função que dá valor a cada estado deve ser dada como parâmetro, as buscas A* e Greedy Best utilizam funções distintas para dar valor a cada estado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
